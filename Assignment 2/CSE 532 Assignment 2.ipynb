{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 532 Assignment \\#2 (Due 3/1/23)\n",
    "An important aspect to text mining and natural language processing is measuring word frequency and trends in word usage.  This assignment deals with a simple exercise in loading a text file into Python and computing word frequency statistics and trends.  It requires usage of text files, strings and dataframes, so it is heavily encouraged that you take a look at relevant sessions (13-17) if you have not already done so.\n",
    "\n",
    "(a) Locate a movie script, play script, poem, or book of your choice in .txt format. You are free to choose nearly any novel, movie script, or play that you like, with the qualification that your chosen document **must have a minimum of 5 chapters, scenes, and/or acts that distinguish one portion of the document's narrative from another**.  For example, the novel \"Great Expectations\" has 59 chapters, the script for \"Jaws\" has about 27 scenes, and all or almost all Shakespearean plays have exactly five acts. It is important that for part (e) of the document that these segments exist for your document. [Project Gutenburg](https://www.gutenberg.org/) is a great resource for this if you're not sure where to start.  **Make sure you include your text file in your submission.  If your document has a particularly large number of segments, it is okay to trim the document to something more manageable (ex: working with only chapters 1-20 of \"Great Expectations.\")**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**You can use .py files, .ipynb files, or a combination of the two in your solution.  Zip these file(s) along with a simple README telling us what to run to generate the list, data-frames, and plots into a zip file with the name <LN_FN_2.zip>, where LN is your last-name and FN is your first-name, and submit this file to Blackboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Load the words of this structure in sequential order of appearance into a one-dimensional Python list (i.e. the first word should be the first element in the list, while the last word should be the last element) that is **case insensitive**.  It's up to you how to deal with special chacters -- you can remove them manually, ignore them during the loading process, or even count them as words, for example.  **Make sure you have this list clearly assigned to a variable, so we can evaluate it during grading.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Use your list to create **and print** a two-column pandas data-frame with the following properties: <br>\n",
    "i. The first column for each index should represent the word in question at that index <br>\n",
    "ii. The second column should represent the number of times that particular word appears in the text. <br>\n",
    "iii. The rows of the data-frame should be ordered according to the **first** occurrence of each word. <br>\n",
    "iv. It's up to you whether or not your data-frame will include an index per row.  <br>**Make sure you have this data-frame clearly assigned to a variable, so we can evaluate it during grading.**\n",
    "\n",
    "Ex: if the first word in your text is \"the\" which occurs 500 times and the second is \"balcony\" which only appears twice, your data-frame should _begin_ like the following:\n",
    "\n",
    "| | Word | Count |\n",
    "| --- | --- | --- |\n",
    "| 1 | \"the\" | 500 |\n",
    "| 2 | \"balcony\" | 2 |\n",
    "| ... | ... | ... |\n",
    "Again, the indices are optional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) **Stop-words** are commonly used words in a given language that often fail to communicate useful summative information about its content.  The attached file \"stop_words.txt\" has a simple list of common stop words assigned to a variable.  For this part of the assigment, you are to create a modified copy of the data-frame from (c) with the following modifications: _i. all stop words have been removed from the data-frame_ and _ii. the data frame rows have been sorted in decreasing order of frequency counts_.  **Again, make sure you have this data-frame clearly assigned to a variable, so we can evaluate it during grading.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) While total word counts can provide a useful measure of the content of a document, they cannot reveal much about its underlying trends.  In the context of document analysis, the term _trend_ implies a direction (in terms of theme, mood, etc.) in which the content changes throughout the narrative.  For example, some works of fiction begin with a comedic tone, and take on a more serious tone in later stages, or vice versa.  While tone shifts are a bit beyond the scope of this assignment, it *is* feasible to monitor which **words** become more or less common within the document over time (ex: a character killed in the first act of a screenplay will *potentially* appear less frequently in subsequent acts).  For the last part of your assignment, you are to do the following: <br>\n",
    "i. Use your dataframe from part d to pinpoint the six most commonly occurring words in your text (if there are stop-words that were not successfully excluded programmatically in part d due to punctuation, etc., you should manually exclude them here). <br>\n",
    "ii. For each of the six words, compute the ratio of its appearances per narrative segment (chapter, act, etc.) compared to the sum across the work overall.  These quantities can be either in percentile or decimal. <br>\n",
    "iii. You are then to create a 2 x 3 or 3 x 2 series of subplots and, for each of the six words, provide a bar graph that depicts the ratios (not raw counts) across segments.\n",
    "\n",
    "As an example, suppose a hypothetical work has five chapters, and one of the six most common words is \"Barcelona\"; further, suppose this word appears 10, 20, 15, 5, and 0 times in chapters 1, 2, 3, 4, and 5 respectively.  The bar graph for this plot should look something like the below: <br>\n",
    "![Barcelona Trends Bar Graph](barcelonatrends.png \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
